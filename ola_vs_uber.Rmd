---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
library(ggplot2)
library(gridExtra)
library(tidytext)
library(dplyr)
library(topicmodels)
library(quanteda)
library(wordcloud)
```



```{r}
# Load the CSV file into a data frame
uber_reviews <- read.csv("Uber_Customer_Reviews.csv", header = TRUE)
ola_reviews <- read.csv("Ola_Customer_Reviews.csv", header = TRUE)

# Check the structure of the data frame
str(uber_reviews)
str(ola_reviews)
```
```{r}
summary(uber_reviews)
summary(ola_reviews)
```


```{r}
#Rating Count
uber_rating_counts <- table(uber_reviews$rating)
ola_rating_counts <- table(ola_reviews$rating)
uber_rating_counts
ola_rating_counts
```


```{r}
# hightest thumbs_up reviews
#Uber
# Filter for reviews with a rating of 5
top_comments_5 <- uber_reviews[uber_reviews$rating == 5, ]

# Filter for reviews with a rating of 1
top_comments_1 <- uber_reviews[uber_reviews$rating == 1, ]

# Sort the data frames by thumbs up count in descending order
top_comments_5 <- top_comments_5[order(-top_comments_5$thumbs_up), ]
top_comments_1 <- top_comments_1[order(-top_comments_1$thumbs_up), ]

# Select the top 5 comments and thumbs up counts for each rating
top_5_comments_thumbs_up_5 <- top_comments_5[1:5, c("review_description", "thumbs_up")]
top_5_comments_thumbs_up_1 <- top_comments_1[1:5, c("review_description", "thumbs_up")]

# Print the top 5 comments and thumbs up counts for each rating
print("Top 5 comments with thumbs up count for rating 5:")
print(top_5_comments_thumbs_up_5)

print("Top 5 comments with thumbs up count for rating 1:")
print(top_5_comments_thumbs_up_1)
```


```{r}
# hightest thumbs_up reviews
#OLA
# Filter for reviews with a rating of 5
top_comments_5 <- ola_reviews[ola_reviews$rating == 5, ]

# Filter for reviews with a rating of 1
top_comments_1 <- ola_reviews[ola_reviews$rating == 1, ]

# Sort the data frames by thumbs up count in descending order
top_comments_5 <- top_comments_5[order(-top_comments_5$thumbs_up), ]
top_comments_1 <- top_comments_1[order(-top_comments_1$thumbs_up), ]

# Select the top 5 comments and thumbs up counts for each rating
top_5_comments_thumbs_up_5 <- top_comments_5[1:5, c("review_description", "thumbs_up")]
top_5_comments_thumbs_up_1 <- top_comments_1[1:5, c("review_description", "thumbs_up")]

# Print the top 5 comments and thumbs up counts for each rating
print("Top 5 comments with thumbs up count for rating 5:")
print(top_5_comments_thumbs_up_5)

print("Top 5 comments with thumbs up count for rating 1:")
print(top_5_comments_thumbs_up_1)
```

```{r}
# Distribution Comparision of Ratings
p_ola <- ggplot(ola_reviews, aes(x = rating)) +
  geom_histogram(binwidth = 1, fill = "skyblue", color = "black") +
  labs(title = "Ola Rating Distribution", x = "Rating", y = "Count")

p_uber <- ggplot(uber_reviews, aes(x = rating)) +
  geom_histogram(binwidth = 1, fill = "lightgreen", color = "black") +
  labs(title = "Uber Rating Distribution", x = "Rating", y = "Count")

# Combine the plots
plot_combined <- grid.arrange(p_ola, p_uber, ncol = 2)

# Print the combined plot
print(plot_combined)
```
```{r}
#Temporal Analysis (Time Series Analysis)
ola_reviews$review_date <- as.Date(ola_reviews$review_date)
plot_line_ola <- ggplot(ola_reviews, aes(x = review_date)) +
  geom_line(stat = "count") +
  labs(title = "(OLA) Number of Reviews Over Time", x = "Date", y = "Number of Reviews")

uber_reviews$review_date <- as.Date(uber_reviews$review_date)
plot_line_uber <- ggplot(uber_reviews, aes(x = review_date)) +
  geom_line(stat = "count") +
  labs(title = "(UBER) Number of Reviews Over Time", x = "Date", y = "Number of Reviews")

plot_line_ola
plot_line_uber

# Combine the plots
plot_line_combined <- grid.arrange(plot_line_ola, plot_line_uber, ncol=1)
```
```{r}
#Topic Modeling
#Uber
#Pre-process
uber_clean_reviews <- uber_reviews %>%
   mutate(review_description = tolower(review_description)) %>%
  unnest_tokens(word, review_description) %>%
  anti_join(stop_words)


# Document-Term Matrix
uber_word_counts_dtm = uber_clean_reviews %>% count(review_id, word) %>% cast_dfm(review_id, word, n)
uber_word_counts_dtm
```


```{r}
#OLa
#Pre-process
ola_clean_reviews <- ola_reviews %>%
   mutate(review_description = tolower(review_description)) %>%
  unnest_tokens(word, review_description) %>%
  anti_join(stop_words)


# Document-Term Matrix
ola_word_counts_dtm = ola_clean_reviews %>% count(review_id, word) %>% cast_dfm(review_id, word, n)
ola_word_counts_dtm
```


```{r}
# check the top features
print("Uber 20 Top Words")
topfeatures(uber_word_counts_dtm, n = 20, scheme = "docfreq")

print("Ola 20 Top Words")
topfeatures(ola_word_counts_dtm, n = 20, scheme = "docfreq")
```


```{r}
# Topic Model Training
lda_model_uber <- LDA(uber_word_counts_dtm, k = 2)
lda_model_ola <- LDA(ola_word_counts_dtm, k = 2)
```

```{r}
lda_model_ola
```
```{r}
terms(lda_model_uber, 15)
terms(lda_model_ola, 15)
```


```{r}
# Word-topic probabilities
#uber
uber_lda_topics <-tidy(lda_model_uber,matrix="beta")
uber_lda_topics
```

```{r}
#ola
ola_lda_topics <-tidy(lda_model_ola,matrix="beta")
ola_lda_topics
```


```{r}
uber_top_terms <- uber_lda_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

uber_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()+
  labs(title = "The terms that are most common within each topic")
```

```{r}
ola_top_terms <- ola_lda_topics %>%
  group_by(topic) %>%
  slice_max(beta, n = 15) %>% 
  ungroup() %>%
  arrange(topic, -beta)

ola_top_terms %>%
  mutate(term = reorder_within(term, beta, topic)) %>%
  ggplot(aes(beta, term, fill = factor(topic))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ topic, scales = "free") +
  scale_y_reordered()+
  labs(title = "The terms that are most common within each topic")
```

```{r}
uber_lda_documents <- tidy(lda_model_uber, matrix = "gamma")
uber_lda_documents
```

```{r}
ola_lda_documents <- tidy(lda_model_uber, matrix = "gamma")
ola_lda_documents
```


```{r}
#sentiment analysis
#uber
bing_lexicon <- get_sentiments("bing")

# Perform sentiment analysis by joining Uber reviews with the Bing lexicon
uber_reviews_sentiments <- inner_join(uber_reviews, bing_lexicon, by = c("review_description" = "word"))
uber_reviews_sentiment <- inner_join(uber_reviews, bing_lexicon, by = c("review_description" = "word")) %>%
  count(sentiment) %>%
  mutate(sentiment = factor(sentiment, levels = c("negative", "neutral", "positive")))

ggplot(uber_reviews_sentiment, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(title = "Uber Sentiment Distribution", x = "Sentiment", y = "Count") +
  scale_fill_manual(values = c("negative" = "red", "neutral" = "gray", "positive" = "green"))
```
```{r}
#ola
# Perform sentiment analysis by joining Ola reviews with the Bing lexicon
ola_reviews_sentiments <- inner_join(ola_reviews, bing_lexicon, by = c("review_description" = "word"))
ola_reviews_sentiment <- inner_join(ola_reviews, bing_lexicon, by = c("review_description" = "word")) %>%
  count(sentiment) %>%
  mutate(sentiment = factor(sentiment, levels = c("negative", "neutral", "positive")))

ggplot(ola_reviews_sentiment, aes(x = sentiment, y = n, fill = sentiment)) +
  geom_bar(stat = "identity") +
  labs(title = "Ola Sentiment Distribution", x = "Sentiment", y = "Count") +
  scale_fill_manual(values = c("negative" = "red", "neutral" = "gray", "positive" = "green"))
```


```{r}
df_uber <- cbind(uber_reviews_sentiments$review_description, uber_reviews_sentiments$sentiment)

df_uber <- as.data.frame(df_uber)
colnames(df_uber) <- c("word", "sentiment")

df_uber

df_ola <- cbind(ola_reviews_sentiments$review_description, ola_reviews_sentiments$sentiment)

df_ola <- as.data.frame(df_ola)
colnames(df_ola) <- c("word", "sentiment")

df_ola
```

```{r}
# Generate a word cloud
#Uber
word_freq <- table(df_uber$word)

wordcloud(words = names(word_freq), freq = word_freq, min.freq = 5,
          random.order = FALSE, colors = brewer.pal(8, "Dark2"), scale = c(10, 0.8))

#OLA
word_freq <- table(df_ola$word)

wordcloud(words = names(word_freq), freq = word_freq, min.freq = 5,
          random.order = FALSE, colors = brewer.pal(8, "Dark2"), scale = c(10, 0.8))
```
```{r}
#Common Positive and Negative Words
uber_word_counts <- df_uber %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

uber_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "Uber Contribution to sentiment",
       y = NULL)
```

```{r}
#Common Positive and Negative Words
ola_word_counts <- df_ola %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup()

ola_word_counts %>%
  group_by(sentiment) %>%
  slice_max(n, n = 10) %>% 
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(x = "OLA Contribution to sentiment",
       y = NULL)
```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

